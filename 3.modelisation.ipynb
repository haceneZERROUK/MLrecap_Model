{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3d2b9e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "bda07b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"DATASET_FINAL.json\")\n",
    "# df = df.drop([\"budget\", \"duration\"], axis = 1)\n",
    "df = df.drop([\"duration\"], axis = 1)\n",
    "df[\"country\"] = df[\"country\"].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "9c7738d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fr_title               0\n",
       "released_year          0\n",
       "directors              0\n",
       "writer                 0\n",
       "distribution           0\n",
       "country                0\n",
       "budget              1902\n",
       "category               0\n",
       "released_date          0\n",
       "classification         0\n",
       "weekly_entrances       0\n",
       "duration_minutes       0\n",
       "actor_1                0\n",
       "actor_2                0\n",
       "actor_3                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f7fffa00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fr_title             object\n",
       "released_year         int64\n",
       "directors            object\n",
       "writer               object\n",
       "distribution         object\n",
       "country              object\n",
       "budget              float64\n",
       "category             object\n",
       "released_date        object\n",
       "classification       object\n",
       "weekly_entrances      int64\n",
       "duration_minutes      int64\n",
       "actor_1              object\n",
       "actor_2              object\n",
       "actor_3              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "836e257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conversion de la colonne released_date en datetime\n",
    "df[\"released_date\"] = df[\"released_date\"].str.strip()\n",
    "df[\"released_date\"] = pd.to_datetime(df[\"released_date\"], format='%d/%m/%Y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a6bdf2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df[\"budget\"].isna()]\n",
    "# df[(df[\"country\"] == \"Etats-Unis\") & (df[\"budget\"].isna())].head(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9d9e2f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fr_title                    object\n",
       "released_year                int64\n",
       "directors                   object\n",
       "writer                      object\n",
       "distribution                object\n",
       "country                     object\n",
       "budget                     float64\n",
       "category                    object\n",
       "released_date       datetime64[ns]\n",
       "classification              object\n",
       "weekly_entrances             int64\n",
       "duration_minutes             int64\n",
       "actor_1                     object\n",
       "actor_2                     object\n",
       "actor_3                     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "cae922a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directors :  3441\n",
      "writer :  4286\n",
      "distribution :  1126\n",
      "country :  73\n",
      "category :  23\n",
      "classification :  7\n",
      "actor_1 :  2917\n",
      "actor_2 :  3650\n",
      "actor_3 :  4261\n"
     ]
    }
   ],
   "source": [
    "print(\"directors : \", df[\"directors\"].unique().shape[0])\n",
    "print(\"writer : \", df[\"writer\"].unique().shape[0])\n",
    "print(\"distribution : \", df[\"distribution\"].unique().shape[0])\n",
    "print(\"country : \", df[\"country\"].unique().shape[0])\n",
    "print(\"category : \", df[\"category\"].unique().shape[0])\n",
    "print(\"classification : \", df[\"classification\"].unique().shape[0])\n",
    "print(\"actor_1 : \", df[\"actor_1\"].unique().shape[0])\n",
    "print(\"actor_2 : \", df[\"actor_2\"].unique().shape[0])\n",
    "print(\"actor_3 : \", df[\"actor_3\"].unique().shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "915b41c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.dropna(subset=[\"budget\"], axis=0)\n",
    "\n",
    "# df[df[\"country\"] == \"Japon\"][\"budget\"].median()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "248a9f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7251, 15)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.isna().sum()\n",
    "df.dtypes\n",
    "df[\"directors\"] = df[\"directors\"].rename()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a004c3",
   "metadata": {},
   "source": [
    "# traitements : \n",
    "\n",
    "#### country : \n",
    "One hot encoding\n",
    "regrouper par fréquence (les pays qui produisent le plus - prendre un nombre de film comme seuil - seuil a déterminer par une EDA)\n",
    "    -> garder les 10 pays qui produisent le plus et le reste le mettre dans autres\n",
    "\n",
    "#### category : \n",
    "one hot encoding\n",
    "\n",
    "#### classification : \n",
    "One hot encoding\n",
    "\n",
    "#### director, writer, distribution, actors : \n",
    "nombre d'occurences (fréquence)\n",
    "popularité basée sur les entrées passées\n",
    "classement des plus connus (depuis une liste externe)\n",
    "    - top 100 ?\n",
    "    - top 200 ?\n",
    "    - top 500 ?\n",
    "\n",
    "#### release_date : \n",
    "    - Vacances scolaires\n",
    "    - saisons\n",
    "    - festivals\n",
    "    - Année stratégique\n",
    "        - is_covid_year = df[\"released_year\"].isin([2020, 2021])\n",
    "        - post_streaming = df[\"released_year\"] >= 2012\n",
    "        - release_decade = df[\"released_year\"] // 10 * 10\n",
    "\n",
    "    - apparition des plateformes de streaming\n",
    "    - Semaine spéciale\n",
    "        - is_christmas_week → sortie entre 24 déc - 31 déc\n",
    "        - is_new_year_week → 1er janvier\n",
    "        - is_summer_release → juillet / août\n",
    "        - is_back_to_school → semaine 36-38\n",
    "        - is_award_season → jan-fév (sorties Oscar / César)\n",
    "        - is_festival_period → mai pour Cannes, septembre pour TIFF/Venise\n",
    "\n",
    "#### budget : \n",
    "    - supprimer les budgets extraits de imdb ?\n",
    "    - créer une colonne budget disponible (oui ou non) ?\n",
    "    - Créez des catégories de budget (petit/moyen/gros) quand l'information est disponible ?\n",
    "    - Utilisez \"inconnu\" comme catégorie supplémentaire ?\n",
    "    - supprimer les lignes ou les budgets sont nuls ?\n",
    "\n",
    "###### country          OK\n",
    "###### category         OK\n",
    "###### classification   OK\n",
    "###### director         OK\n",
    "###### writer           OK\n",
    "###### distribution     OK\n",
    "###### actors           OK\n",
    "###### release_date     OK\n",
    "###### release_year     OK\n",
    "###### budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "b87ad18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 15)\n",
      "(105, 15)\n",
      "(128, 15)\n"
     ]
    }
   ],
   "source": [
    "print(df[df[\"actor_1\"] == \"no_actor\"].shape)\n",
    "print(df[df[\"actor_2\"] == \"no_actor\"].shape)\n",
    "print(df[df[\"actor_3\"] == \"no_actor\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2aa4828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification, country, category - one hot encoding ou get dummies\n",
    "\n",
    "df = pd.get_dummies(df, columns=[\"classification\", \"category\", \"country\"], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3e9b3c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# director\n",
    "\n",
    "df_directors = df.groupby('directors')['weekly_entrances'].mean().reset_index()\n",
    "\n",
    "df_directors_low = df_directors[df_directors[\"weekly_entrances\"] < 100000]\n",
    "df_directors_middle = df_directors[(df_directors[\"weekly_entrances\"] >= 100000) & (df_directors[\"weekly_entrances\"] <= 500000)]\n",
    "df_directors_high = df_directors[df_directors[\"weekly_entrances\"] > 500000]\n",
    "\n",
    "df[\"top_director_low\"] = df[\"directors\"].apply(lambda x: 1 if x in df_directors_low[\"directors\"].to_list() else 0)\n",
    "df[\"top_director_middle\"] = df[\"directors\"].apply(lambda x: 1 if x in df_directors_middle[\"directors\"].to_list() else 0)\n",
    "df[\"top_director_high\"] = df[\"directors\"].apply(lambda x: 1 if x in df_directors_high[\"directors\"].to_list() else 0)\n",
    "\n",
    "# df['top_director'] = df['directors'].apply(lambda x : 1 if x in(df_directors['directors'].to_list()) else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c60e7495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer\n",
    "\n",
    "df_writer = df.groupby('writer')['weekly_entrances'].mean().reset_index()\n",
    "\n",
    "df_writer_low = df_writer[df_writer[\"weekly_entrances\"] < 100000]\n",
    "df_writer_middle = df_writer[(df_writer[\"weekly_entrances\"] >= 100000) & (df_writer[\"weekly_entrances\"] <= 500000)]\n",
    "df_writer_high = df_writer[df_writer[\"weekly_entrances\"] > 500000]\n",
    "\n",
    "df[\"top_writer_low\"] = df[\"writer\"].apply(lambda x: 1 if x in df_writer_low[\"writer\"].to_list() else 0)\n",
    "df[\"top_writer_middle\"] = df[\"writer\"].apply(lambda x: 1 if x in df_writer_middle[\"writer\"].to_list() else 0)\n",
    "df[\"top_writer_high\"] = df[\"writer\"].apply(lambda x: 1 if x in df_writer_high[\"writer\"].to_list() else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "efa9c4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution\n",
    "\n",
    "df_distribution = df.groupby('distribution')['weekly_entrances'].mean().reset_index()\n",
    "\n",
    "df_distribution_low = df_distribution[df_distribution[\"weekly_entrances\"] < 100000]\n",
    "df_distribution_middle = df_distribution[(df_distribution[\"weekly_entrances\"] >= 100000) & (df_distribution[\"weekly_entrances\"] <= 500000)]\n",
    "df_distribution_high = df_distribution[df_distribution[\"weekly_entrances\"] > 500000]\n",
    "\n",
    "df[\"top_distribution_low\"] = df[\"distribution\"].apply(lambda x: 1 if x in df_distribution_low[\"distribution\"].to_list() else 0)\n",
    "df[\"top_distribution_middle\"] = df[\"distribution\"].apply(lambda x: 1 if x in df_distribution_middle[\"distribution\"].to_list() else 0)\n",
    "df[\"top_distribution_high\"] = df[\"distribution\"].apply(lambda x: 1 if x in df_distribution_high[\"distribution\"].to_list() else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "97c278fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actor_1\n",
    "\n",
    "df_actor_1 = df.groupby('actor_1')['weekly_entrances'].mean().reset_index()\n",
    "\n",
    "df_actor_1_low = df_actor_1[df_actor_1[\"weekly_entrances\"] < 100000]\n",
    "df_actor_1_middle = df_actor_1[(df_actor_1[\"weekly_entrances\"] >= 100000) & (df_actor_1[\"weekly_entrances\"] <= 500000)]\n",
    "df_actor_1_high = df_actor_1[df_actor_1[\"weekly_entrances\"] > 500000]\n",
    "\n",
    "df[\"top_actor_1_low\"] = df[\"actor_1\"].apply(lambda x: 1 if x in df_actor_1_low[\"actor_1\"].to_list() and x != \"no_actor\" else 0)\n",
    "\n",
    "df[\"top_actor_1_middle\"] = df[\"actor_1\"].apply(lambda x: 1 if x in df_actor_1_middle[\"actor_1\"].to_list() and x != \"no_actor\" else 0)\n",
    "df[\"top_actor_1_high\"] = df[\"actor_1\"].apply(lambda x: 1 if x in df_actor_1_high[\"actor_1\"].to_list() and x != \"no_actor\" else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "33f8d534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actor_2\n",
    "\n",
    "df_actor_2 = df.groupby('actor_2')['weekly_entrances'].mean().reset_index()\n",
    "\n",
    "df_actor_2_low = df_actor_2[df_actor_2[\"weekly_entrances\"] < 100000]\n",
    "df_actor_2_middle = df_actor_2[(df_actor_2[\"weekly_entrances\"] >= 100000) & (df_actor_2[\"weekly_entrances\"] <= 500000)]\n",
    "df_actor_2_high = df_actor_2[df_actor_2[\"weekly_entrances\"] > 500000]\n",
    "\n",
    "df[\"top_actor_2_low\"] = df[\"actor_2\"].apply(lambda x: 1 if x in df_actor_2_low[\"actor_2\"].to_list() else 0)\n",
    "df[\"top_actor_2_middle\"] = df[\"actor_2\"].apply(lambda x: 1 if x in df_actor_2_middle[\"actor_2\"].to_list() else 0)\n",
    "df[\"top_actor_2_high\"] = df[\"actor_2\"].apply(lambda x: 1 if x in df_actor_2_high[\"actor_2\"].to_list() else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "8f952cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actor_3\n",
    "\n",
    "df_actor_3 = df.groupby('actor_3')['weekly_entrances'].mean().reset_index()\n",
    "\n",
    "df_actor_3_low = df_actor_3[df_actor_3[\"weekly_entrances\"] < 100000]\n",
    "df_actor_3_middle = df_actor_3[(df_actor_3[\"weekly_entrances\"] >= 100000) & (df_actor_3[\"weekly_entrances\"] <= 500000)]\n",
    "df_actor_3_high = df_actor_3[df_actor_3[\"weekly_entrances\"] > 500000]\n",
    "\n",
    "df[\"top_actor_3_low\"] = df[\"actor_3\"].apply(lambda x: 1 if x in df_actor_3_low[\"actor_3\"].to_list() else 0)\n",
    "df[\"top_actor_3_middle\"] = df[\"actor_3\"].apply(lambda x: 1 if x in df_actor_3_middle[\"actor_3\"].to_list() else 0)\n",
    "df[\"top_actor_3_high\"] = df[\"actor_3\"].apply(lambda x: 1 if x in df_actor_3_high[\"actor_3\"].to_list() else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b654e940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# release_date\n",
    "\n",
    "\"\"\"\n",
    "#### release_date : \n",
    "    - mois de vacances scolaires (été)\n",
    "    - saisons\n",
    "    - Année stratégique\n",
    "        - is_covid_year = df[\"released_year\"].isin([2020, 2021])\n",
    "        - post_streaming = df[\"released_year\"] >= 2012\n",
    "\n",
    "    - Semaine spéciale\n",
    "        - is_christmas_week → sortie entre 24 déc - 31 déc\n",
    "        - is_new_year_week → 1er janvier\n",
    "            - noel + new year : 20/12 au 05/01\n",
    "        - is_award_season → fev - mars (sorties Oscar / César) \n",
    "\"\"\"\n",
    "\n",
    "df[\"summer\"] = df[\"released_date\"].apply(lambda x: 1 if ((x.month == 6 and x.day >= 21) or x.month in [7, 8] or (x.month == 9 and x.day < 22)) else 0)\n",
    "df[\"automn\"] = df[\"released_date\"].apply(lambda x: 1 if ((x.month == 9 and x.day >= 22) or x.month in [10, 11] or (x.month == 12 and x.day < 21)) else 0)\n",
    "df[\"winter\"] = df[\"released_date\"].apply(lambda x: 1 if ((x.month == 12 and x.day >= 21) or x.month in [1, 2] or (x.month == 3 and x.day < 20)) else 0)\n",
    "df[\"spring\"] = df[\"released_date\"].apply(lambda x: 1 if ((x.month == 3 and x.day >= 21) or x.month in [4, 5] or (x.month == 6 and x.day < 21)) else 0)\n",
    "\n",
    "df[\"is_covid\"] = df[\"released_date\"].apply(lambda x: 1 if (\n",
    "    (x >= pd.to_datetime(\"2020-03-17\") and x <= pd.to_datetime(\"2020-05-11\")) or\n",
    "    (x >= pd.to_datetime(\"2020-10-30\") and x <= pd.to_datetime(\"2020-12-15\")) or\n",
    "    (x >= pd.to_datetime(\"2021-04-03\") and x <= pd.to_datetime(\"2021-05-03\"))\n",
    ") else 0)\n",
    "\n",
    "df[\"post_streaming\"] = df[\"released_date\"].apply(lambda x: 1 if x >= pd.to_datetime(\"2014-09-15\") else 0)\n",
    "\n",
    "df[\"summer_holidays\"] = df[\"released_date\"].apply(lambda x: 1 if x.month >= 7 or (x.month <= 9 and x.day < 10) else 0)\n",
    "\n",
    "df[\"christmas_period\"] = df[\"released_date\"].apply(lambda x: 1 if (x.month == 12 and x.day >= 20) or (x.month == 1 and x.day <= 5) else 0)\n",
    "\n",
    "df[\"is_award_season\"] = df[\"released_date\"].apply(lambda x: 1 if (x.month == 2 or (x.month == 3 and x.day <= 10)) else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b35db719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autres transformations \n",
    "\n",
    "# Mois et transformations cycliques (capture mieux les patterns saisonniers)\n",
    "df['month'] = df['released_date'].dt.month\n",
    "df['cos_month'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "df['sin_month'] = np.sin(2 * np.pi * df['month'] / 12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "3ba2ec54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Créer des bins plus détaillés pour une meilleure stratification\n",
    "# df['success_level'] = pd.cut(df['weekly_entrances'],\n",
    "#                             bins=[0, 50000, 200000, 500000, 1000000, float('inf')],\n",
    "#                             labels=[0, 1, 2, 3, 4])\n",
    "\n",
    "# df = df.dropna(subset=[\"budget\"])\n",
    "# X = df.drop(\"weekly_entrances\", axis = 1)\n",
    "# y = df[\"weekly_entrances\"]\n",
    "\n",
    "\n",
    "# # Stratifier sur ces niveaux\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.15, random_state=42, stratify=df['success_level']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "94c04141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7251, 142)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2e64cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea27e337",
   "metadata": {},
   "source": [
    "# Modélisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "6c236fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "0360b151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df_initial.select_dtypes(exclude=\"object\")\n",
    "df = df_initial.select_dtypes(exclude=[\"object\", \"datetime\"]).drop([\"released_year\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "48d993c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['budget',\n",
       " 'weekly_entrances',\n",
       " 'duration_minutes',\n",
       " 'classification_Interdit - 12 ans',\n",
       " 'classification_Interdit - 16 ans',\n",
       " 'classification_Interdit - 18 ans',\n",
       " 'classification_Interdit - 6 ans',\n",
       " 'classification_Interdit - 8 ans',\n",
       " 'classification_Tout public',\n",
       " 'category_Adaptation Livre',\n",
       " 'category_Animation',\n",
       " 'category_Aventure - Action',\n",
       " 'category_Catastrophe',\n",
       " 'category_Comicbook',\n",
       " 'category_Comédie',\n",
       " 'category_Comédie dramatique',\n",
       " 'category_Court-métrage',\n",
       " 'category_Documentaire',\n",
       " 'category_Drame',\n",
       " 'category_Fantasy',\n",
       " 'category_Film familial',\n",
       " 'category_Guerre',\n",
       " 'category_Horreur',\n",
       " 'category_Musical',\n",
       " 'category_Parodie',\n",
       " 'category_Péplum',\n",
       " 'category_Romance',\n",
       " 'category_Science Fiction',\n",
       " 'category_Thriller',\n",
       " 'category_Western',\n",
       " 'category_X - Erotique',\n",
       " 'country_Afghanistan',\n",
       " 'country_Afrique du Sud',\n",
       " 'country_Algérie',\n",
       " 'country_Allemagne',\n",
       " 'country_Arabie Saoudite',\n",
       " 'country_Argentine',\n",
       " 'country_Australie',\n",
       " 'country_Autriche',\n",
       " 'country_Belgique',\n",
       " 'country_Bosnie',\n",
       " 'country_Bouthan',\n",
       " 'country_Brésil',\n",
       " 'country_Bulgarie',\n",
       " 'country_Canada',\n",
       " 'country_Chili',\n",
       " 'country_Chine',\n",
       " 'country_Colombie',\n",
       " 'country_Corée du Sud',\n",
       " 'country_Cuba',\n",
       " 'country_Danemark',\n",
       " 'country_Egypte',\n",
       " 'country_Espagne',\n",
       " 'country_Estonie',\n",
       " 'country_Etats-Unis',\n",
       " 'country_Finlande',\n",
       " 'country_France',\n",
       " 'country_Georgie',\n",
       " 'country_Grande-Bretagne',\n",
       " 'country_Grèce',\n",
       " 'country_Guatemala',\n",
       " 'country_Hongrie',\n",
       " 'country_Inde',\n",
       " 'country_Indonésie',\n",
       " 'country_Iran',\n",
       " 'country_Irlande',\n",
       " 'country_Islande',\n",
       " 'country_Israël',\n",
       " 'country_Italie',\n",
       " 'country_Japon',\n",
       " 'country_Jordanie',\n",
       " 'country_Lettonie',\n",
       " 'country_Liban',\n",
       " 'country_Lituanie',\n",
       " 'country_Luxembourg',\n",
       " 'country_Macédoine',\n",
       " 'country_Maroc',\n",
       " 'country_Mexique',\n",
       " 'country_Mongolie',\n",
       " 'country_Norvège',\n",
       " 'country_Nouvelle-Zélande',\n",
       " 'country_Palestine',\n",
       " 'country_Paraguay',\n",
       " 'country_Pays-Bas',\n",
       " 'country_Philippines',\n",
       " 'country_Pologne',\n",
       " 'country_Portugal',\n",
       " 'country_Pérou',\n",
       " 'country_Roumanie',\n",
       " 'country_Russie',\n",
       " 'country_Rép. Tchèque',\n",
       " 'country_Serbie',\n",
       " 'country_Singapour',\n",
       " 'country_Suisse',\n",
       " 'country_Suède',\n",
       " 'country_Taïwan',\n",
       " 'country_Thaïlande',\n",
       " 'country_Tunisie',\n",
       " 'country_Turquie',\n",
       " 'country_Ukraine',\n",
       " 'country_Uruguay',\n",
       " 'country_Venezuela',\n",
       " 'country_Viet-Nam',\n",
       " 'top_director_low',\n",
       " 'top_director_middle',\n",
       " 'top_director_high',\n",
       " 'top_writer_low',\n",
       " 'top_writer_middle',\n",
       " 'top_writer_high',\n",
       " 'top_distribution_low',\n",
       " 'top_distribution_middle',\n",
       " 'top_distribution_high',\n",
       " 'top_actor_1_low',\n",
       " 'top_actor_1_middle',\n",
       " 'top_actor_1_high',\n",
       " 'top_actor_2_low',\n",
       " 'top_actor_2_middle',\n",
       " 'top_actor_2_high',\n",
       " 'top_actor_3_low',\n",
       " 'top_actor_3_middle',\n",
       " 'top_actor_3_high',\n",
       " 'summer',\n",
       " 'automn',\n",
       " 'winter',\n",
       " 'spring',\n",
       " 'is_covid',\n",
       " 'post_streaming',\n",
       " 'summer_holidays',\n",
       " 'christmas_period',\n",
       " 'is_award_season',\n",
       " 'month',\n",
       " 'cos_month',\n",
       " 'sin_month']"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "16f5bf07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([dtype('float64'), dtype('int64'), dtype('bool'), dtype('int32')],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "550f5b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>weekly_entrances</th>\n",
       "      <th>duration_minutes</th>\n",
       "      <th>classification_Interdit - 12 ans</th>\n",
       "      <th>classification_Interdit - 16 ans</th>\n",
       "      <th>classification_Interdit - 18 ans</th>\n",
       "      <th>classification_Interdit - 6 ans</th>\n",
       "      <th>classification_Interdit - 8 ans</th>\n",
       "      <th>classification_Tout public</th>\n",
       "      <th>category_Adaptation Livre</th>\n",
       "      <th>...</th>\n",
       "      <th>winter</th>\n",
       "      <th>spring</th>\n",
       "      <th>is_covid</th>\n",
       "      <th>post_streaming</th>\n",
       "      <th>summer_holidays</th>\n",
       "      <th>christmas_period</th>\n",
       "      <th>is_award_season</th>\n",
       "      <th>month</th>\n",
       "      <th>cos_month</th>\n",
       "      <th>sin_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27800000.0</td>\n",
       "      <td>2429906</td>\n",
       "      <td>107</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24434009.0</td>\n",
       "      <td>2587056</td>\n",
       "      <td>108</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       budget  weekly_entrances  duration_minutes  \\\n",
       "0  27800000.0           2429906               107   \n",
       "1  24434009.0           2587056               108   \n",
       "\n",
       "   classification_Interdit - 12 ans  classification_Interdit - 16 ans  \\\n",
       "0                             False                             False   \n",
       "1                             False                             False   \n",
       "\n",
       "   classification_Interdit - 18 ans  classification_Interdit - 6 ans  \\\n",
       "0                             False                            False   \n",
       "1                             False                            False   \n",
       "\n",
       "   classification_Interdit - 8 ans  classification_Tout public  \\\n",
       "0                            False                        True   \n",
       "1                            False                       False   \n",
       "\n",
       "   category_Adaptation Livre  ...  winter  spring  is_covid  post_streaming  \\\n",
       "0                      False  ...       1       0         0               1   \n",
       "1                      False  ...       1       0         0               0   \n",
       "\n",
       "   summer_holidays  christmas_period  is_award_season  month  cos_month  \\\n",
       "0                0                 0                1      2        0.5   \n",
       "1                1                 0                1      2        0.5   \n",
       "\n",
       "   sin_month  \n",
       "0   0.866025  \n",
       "1   0.866025  \n",
       "\n",
       "[2 rows x 133 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15477924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c04972b",
   "metadata": {},
   "source": [
    "## premier modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "05288ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Créer des bins plus détaillés pour une meilleure stratification\n",
    "df['success_level'] = pd.cut(df['weekly_entrances'],\n",
    "                            bins=[0, 50000, 200000, 500000, 1000000, float('inf')],\n",
    "                            labels=[0, 1, 2, 3, 4])\n",
    "\n",
    "# df = df.dropna(subset=[\"budget\"])\n",
    "df = df.drop([\"budget\"], axis = 1)\n",
    "X = df.drop(\"weekly_entrances\", axis = 1)\n",
    "y = df[\"weekly_entrances\"]\n",
    "\n",
    "\n",
    "# Stratifier sur ces niveaux\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=42, stratify=df['success_level']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5e540cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, median_absolute_error\n",
    "\n",
    "def metriques(model, X_test, y_test) : \n",
    "    \n",
    "    pred_y = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, pred_y)\n",
    "    mae = mean_absolute_error(y_test, pred_y)\n",
    "    r2 = r2_score(y_test, pred_y)\n",
    "    med_ae = median_absolute_error(y_test, pred_y)\n",
    "    \n",
    "    \n",
    "    print(f\"MSE : {mse}\")\n",
    "    print(f\"RMSE : {np.sqrt(mse)}\")\n",
    "    print(f\"MAE : {mae}\")\n",
    "    print(f\"R2 : {r2}\")\n",
    "    print(f\"MedAE : {med_ae}\")\n",
    "    \n",
    "    return mse, mae, r2, med_ae\n",
    "\n",
    "\n",
    "def coefficients(model, X) : \n",
    "    coefs = model.coef_\n",
    "    noms_cols = X.columns\n",
    "    coefs_df = pd.DataFrame({\"variables\" : noms_cols, \"coef\" : coefs})\n",
    "    print(\"coefficients des variables\")\n",
    "    print(coefs_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "908cb86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "cat_features = [i for i, col in enumerate(X_train.columns) if X_train[col].dtype.name == 'category']\n",
    "\n",
    "models = {\n",
    "    \"model_lr\": LinearRegression(),\n",
    "    \"model_lasso\": Lasso(alpha=0.0001),\n",
    "    \"model_ridge\": Ridge(alpha=0.7),\n",
    "    \"model_rf\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"model_gbr\": GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    \"model_xgb\": XGBRegressor(n_estimators=100, random_state=42, enable_categorical=True),\n",
    "    \"model_lgbm\": LGBMRegressor(n_estimators=100, random_state=42),\n",
    "    \"model_catboost\": CatBoostRegressor(iterations=300, random_seed=42, depth=6, verbose=0), \n",
    "    \"model_svr\": SVR(kernel='rbf', C=1.0, epsilon=0.1),\n",
    "    \"model_knn\": KNeighborsRegressor(n_neighbors=5),\n",
    "    \"model_dt\": DecisionTreeRegressor(max_depth=10, random_state=42),\n",
    "    \"model_ada\": AdaBoostRegressor(random_state=42)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "9e4a4f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entrainement du modele model_lr : \n",
      "\n",
      "résultats du model model_lr \n",
      "\n",
      "MSE : 36229959310.388145\n",
      "RMSE : 190341.69094128627\n",
      "MAE : 97107.57588855366\n",
      "R2 : 0.7404778166321538\n",
      "MedAE : 65883.27174741557\n",
      "\n",
      "----------------- \n",
      "\n",
      "entrainement du modele model_lasso : \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/malek/BRIEFS DEV IA/9. MLRecap/MLrecap_Model/.venv/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.633e+13, tolerance: 7.168e+10\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "résultats du model model_lasso \n",
      "\n",
      "MSE : 36217259904.54655\n",
      "RMSE : 190308.32852123564\n",
      "MAE : 97033.3214371717\n",
      "R2 : 0.7405687849245345\n",
      "MedAE : 65659.30152105124\n",
      "\n",
      "----------------- \n",
      "\n",
      "entrainement du modele model_ridge : \n",
      "\n",
      "résultats du model model_ridge \n",
      "\n",
      "MSE : 36188372925.33281\n",
      "RMSE : 190232.41817664204\n",
      "MAE : 96859.6292001388\n",
      "R2 : 0.7407757079258059\n",
      "MedAE : 65206.66626538752\n",
      "\n",
      "----------------- \n",
      "\n",
      "entrainement du modele model_rf : \n",
      "\n",
      "résultats du model model_rf \n",
      "\n",
      "MSE : 17777576701.019444\n",
      "RMSE : 133332.5792933574\n",
      "MAE : 49302.41833336981\n",
      "R2 : 0.8726557907252452\n",
      "MedAE : 18587.025\n",
      "\n",
      "----------------- \n",
      "\n",
      "entrainement du modele model_gbr : \n",
      "\n",
      "résultats du model model_gbr \n",
      "\n",
      "MSE : 19540249191.247856\n",
      "RMSE : 139786.44137128556\n",
      "MAE : 49198.263182752125\n",
      "R2 : 0.860029427849498\n",
      "MedAE : 20146.104215153515\n",
      "\n",
      "----------------- \n",
      "\n",
      "entrainement du modele model_xgb : \n",
      "\n",
      "résultats du model model_xgb \n",
      "\n",
      "MSE : 19060197376.0\n",
      "RMSE : 138058.67367174002\n",
      "MAE : 50378.66796875\n",
      "R2 : 0.8634681105613708\n",
      "MedAE : 18432.7578125\n",
      "\n",
      "----------------- \n",
      "\n",
      "entrainement du modele model_lgbm : \n",
      "\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000203 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 279\n",
      "[LightGBM] [Info] Number of data points in the train set: 6163, number of used features: 66\n",
      "[LightGBM] [Info] Start training from score 207531.522635\n",
      "résultats du model model_lgbm \n",
      "\n",
      "MSE : 18205288096.397034\n",
      "RMSE : 134926.97319808605\n",
      "MAE : 49235.675179159545\n",
      "R2 : 0.8695920115410419\n",
      "MedAE : 17695.399077592112\n",
      "\n",
      "----------------- \n",
      "\n",
      "entrainement du modele model_catboost : \n",
      "\n",
      "résultats du model model_catboost \n",
      "\n",
      "MSE : 17555593099.27465\n",
      "RMSE : 132497.52110614994\n",
      "MAE : 48954.60405060408\n",
      "R2 : 0.8742459020610907\n",
      "MedAE : 17805.573572957685\n",
      "\n",
      "----------------- \n",
      "\n",
      "entrainement du modele model_svr : \n",
      "\n",
      "résultats du model model_svr \n",
      "\n",
      "MSE : 153664873017.29572\n",
      "RMSE : 392001.1135408874\n",
      "MAE : 177845.0849311913\n",
      "R2 : -0.10073111070143725\n",
      "MedAE : 76040.19008132216\n",
      "\n",
      "----------------- \n",
      "\n",
      "entrainement du modele model_knn : \n",
      "\n",
      "résultats du model model_knn \n",
      "\n",
      "MSE : 39234221031.092834\n",
      "RMSE : 198076.3010334473\n",
      "MAE : 85706.58694852941\n",
      "R2 : 0.7189577107306777\n",
      "MedAE : 33530.0\n",
      "\n",
      "----------------- \n",
      "\n",
      "entrainement du modele model_dt : \n",
      "\n",
      "résultats du model model_dt \n",
      "\n",
      "MSE : 30083152638.158405\n",
      "RMSE : 173444.9556434502\n",
      "MAE : 56772.06551861991\n",
      "R2 : 0.7845085778773013\n",
      "MedAE : 17935.19903741655\n",
      "\n",
      "----------------- \n",
      "\n",
      "entrainement du modele model_ada : \n",
      "\n",
      "résultats du model model_ada \n",
      "\n",
      "MSE : 21515132732.53275\n",
      "RMSE : 146680.37609896134\n",
      "MAE : 70330.13628457724\n",
      "R2 : 0.8458829563025503\n",
      "MedAE : 52550.94592476489\n",
      "\n",
      "----------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Entraînement avec pondération des échantillons\n",
    "sample_weights = np.ones(len(y_train))\n",
    "success_mask = y_train > 500000\n",
    "sample_weights[success_mask] = 5  # Pondération 3x plus importante\n",
    "\n",
    "for m in models.keys():\n",
    "    print(f\"entrainement du modele {m} : \\n\")\n",
    "\n",
    "    if m == \"model_catboost\":\n",
    "        models[m].fit(X_train, y_train, cat_features=cat_features)\n",
    "    else:\n",
    "        models[m].fit(X_train, y_train)\n",
    "\n",
    "    print(f\"résultats du model {m} \\n\")\n",
    "    metriques(models[m], X_test=X_test, y_test=y_test)\n",
    "    print(\"\\n----------------- \\n\")    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "4d39f6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultats CatBoost :\n",
      "MSE : 15980268168.587412\n",
      "RMSE : 126413.08543259045\n",
      "MAE : 48041.17937082459\n",
      "R2 : 0.8855302582488308\n",
      "MedAE : 18360.994160578084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15980268168.587412,\n",
       " 48041.17937082459,\n",
       " 0.8855302582488308,\n",
       " np.float64(18360.994160578084))"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# catboost TOP résultats aussi\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "model_catboost = CatBoostRegressor(iterations=100, random_seed=42, depth=6, verbose=0)\n",
    "\n",
    "\n",
    "model_catboost.fit(X_train, y_train, cat_features=cat_features)\n",
    "print(\"Résultats CatBoost :\")\n",
    "metriques(model_catboost, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "13259b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_params = [\n",
    "    {  # Pour grow_policy=SymmetricTree/Depthwise\n",
    "        'grow_policy': ['SymmetricTree', 'Depthwise'],\n",
    "        'iterations': [150, 200, 250, 300],\n",
    "        'learning_rate': [0.03, 0.05, 0.07, 0.1],\n",
    "        'depth': [5, 6, 7, 8],\n",
    "        'min_data_in_leaf': [1, 5, 10, 20],\n",
    "        'l2_leaf_reg': [1, 3, 5, 7],\n",
    "        'random_strength': [0.5, 1.0, 1.5]\n",
    "    },\n",
    "    {  # Pour grow_policy=Lossguide\n",
    "        'grow_policy': ['Lossguide'],\n",
    "        'max_leaves': [31, 55, 80],\n",
    "        'iterations': [150, 200, 250, 300],\n",
    "        'learning_rate': [0.03, 0.05, 0.07, 0.1],\n",
    "        'min_data_in_leaf': [1, 5, 10, 20],\n",
    "        'l2_leaf_reg': [1, 3, 5, 7],\n",
    "        'random_strength': [0.5, 1.0, 1.5]\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "8e021e04",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 250 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n250 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/malek/BRIEFS DEV IA/9. MLRecap/MLrecap_Model/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/malek/BRIEFS DEV IA/9. MLRecap/MLrecap_Model/.venv/lib/python3.11/site-packages/catboost/core.py\", line 5873, in fit\n    return self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline,\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/malek/BRIEFS DEV IA/9. MLRecap/MLrecap_Model/.venv/lib/python3.11/site-packages/catboost/core.py\", line 2410, in _fit\n    self._train(\n  File \"/home/malek/BRIEFS DEV IA/9. MLRecap/MLrecap_Model/.venv/lib/python3.11/site-packages/catboost/core.py\", line 1790, in _train\n    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n  File \"_catboost.pyx\", line 5023, in _catboost._CatBoost._train\n  File \"_catboost.pyx\", line 5072, in _catboost._CatBoost._train\n_catboost.CatBoostError: catboost/cuda/cuda_lib/cuda_manager.cpp:201: Condition violated: `State == nullptr'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[196]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomizedSearchCV\n\u001b[32m      3\u001b[39m random_search = RandomizedSearchCV(\n\u001b[32m      4\u001b[39m     CatBoostRegressor(task_type=\u001b[33m'\u001b[39m\u001b[33mGPU\u001b[39m\u001b[33m'\u001b[39m, devices=\u001b[33m'\u001b[39m\u001b[33m0\u001b[39m\u001b[33m'\u001b[39m, verbose=\u001b[32m0\u001b[39m),\n\u001b[32m      5\u001b[39m     param_distributions=catboost_params[\u001b[32m1\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m     n_jobs=\u001b[32m1\u001b[39m  \u001b[38;5;66;03m# Important pour GPU\u001b[39;00m\n\u001b[32m     11\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mrandom_search\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMeilleurs paramètres: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrandom_search.best_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/BRIEFS DEV IA/9. MLRecap/MLrecap_Model/.venv/lib/python3.11/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/BRIEFS DEV IA/9. MLRecap/MLrecap_Model/.venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/BRIEFS DEV IA/9. MLRecap/MLrecap_Model/.venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1951\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1950\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1951\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1952\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1953\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   1954\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1955\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/BRIEFS DEV IA/9. MLRecap/MLrecap_Model/.venv/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1001\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    994\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) != n_candidates * n_splits:\n\u001b[32m    995\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    996\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcv.split and cv.get_n_splits returned \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    997\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    998\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(n_splits, \u001b[38;5;28mlen\u001b[39m(out) // n_candidates)\n\u001b[32m    999\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1001\u001b[39m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[32m   1004\u001b[39m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[32m   1005\u001b[39m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[32m   1006\u001b[39m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[32m   1007\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m.scoring):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/BRIEFS DEV IA/9. MLRecap/MLrecap_Model/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:517\u001b[39m, in \u001b[36m_warn_or_raise_about_fit_failures\u001b[39m\u001b[34m(results, error_score)\u001b[39m\n\u001b[32m    510\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits == num_fits:\n\u001b[32m    511\u001b[39m     all_fits_failed_message = (\n\u001b[32m    512\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    513\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    514\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou can try to debug the error by setting error_score=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    516\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[32m    519\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    520\u001b[39m     some_fits_failed_message = (\n\u001b[32m    521\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    522\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe score on these train-test partitions for these parameters\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    526\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    527\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: \nAll the 250 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n250 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/home/malek/BRIEFS DEV IA/9. MLRecap/MLrecap_Model/.venv/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/home/malek/BRIEFS DEV IA/9. MLRecap/MLrecap_Model/.venv/lib/python3.11/site-packages/catboost/core.py\", line 5873, in fit\n    return self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline,\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/malek/BRIEFS DEV IA/9. MLRecap/MLrecap_Model/.venv/lib/python3.11/site-packages/catboost/core.py\", line 2410, in _fit\n    self._train(\n  File \"/home/malek/BRIEFS DEV IA/9. MLRecap/MLrecap_Model/.venv/lib/python3.11/site-packages/catboost/core.py\", line 1790, in _train\n    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n  File \"_catboost.pyx\", line 5023, in _catboost._CatBoost._train\n  File \"_catboost.pyx\", line 5072, in _catboost._CatBoost._train\n_catboost.CatBoostError: catboost/cuda/cuda_lib/cuda_manager.cpp:201: Condition violated: `State == nullptr'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    CatBoostRegressor(task_type='GPU', devices='0', verbose=0),\n",
    "    param_distributions=catboost_params[1],\n",
    "    n_iter=50,  # Nombre d'itérations\n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    random_state=42,\n",
    "    n_jobs=1  # Important pour GPU\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train, cat_features=cat_features)\n",
    "print(f\"Meilleurs paramètres: {random_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d2b79f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Après avoir trouvé les meilleurs paramètres avec la recherche grossière\n",
    "# best_params = random_search.best_params_\n",
    "\n",
    "# # Créer une grille fine autour des meilleurs paramètres\n",
    "# fine_params = {\n",
    "#     'iterations': [best_params['iterations'] - 50, best_params['iterations'], best_params['iterations'] + 50],\n",
    "#     'learning_rate': [best_params['learning_rate'] * 0.8, best_params['learning_rate'], best_params['learning_rate'] * 1.2],\n",
    "#     'depth': [max(1, best_params['depth'] - 1), best_params['depth'], best_params['depth'] + 1],\n",
    "#     'l2_leaf_reg': [max(1, best_params['l2_leaf_reg'] - 1), best_params['l2_leaf_reg'], best_params['l2_leaf_reg'] + 1]\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(\n",
    "#     CatBoostRegressor(verbose=0, **{k: v for k, v in best_params.items() if k not in fine_params}),\n",
    "#     param_grid=fine_params,\n",
    "#     cv=5,\n",
    "#     scoring='neg_root_mean_squared_error',\n",
    "#     n_jobs=1\n",
    "# )\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# print(f\"Paramètres optimaux: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "6a5fbd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Créer le modèle final avec les meilleurs paramètres\n",
    "# best_params = grid_search.best_params_\n",
    "# print(\"Meilleurs paramètres trouvés:\", best_params)\n",
    "\n",
    "# # Créer et entraîner le modèle final\n",
    "# final_model = CatBoostRegressor(\n",
    "#     **best_params,\n",
    "#     task_type='GPU',\n",
    "#     devices='0',\n",
    "#     verbose=0\n",
    "# )\n",
    "\n",
    "# # Entraîner sur l'ensemble des données d'entraînement\n",
    "# final_model.fit(X_train, y_train)\n",
    "\n",
    "# # Évaluer sur l'ensemble de test\n",
    "# def metriques_detaillees(model, X_test, y_test):\n",
    "#     # Prédictions\n",
    "#     pred_y = model.predict(X_test)\n",
    "\n",
    "#     # Métriques globales\n",
    "#     mse = mean_squared_error(y_test, pred_y)\n",
    "#     rmse = np.sqrt(mse)\n",
    "#     mae = mean_absolute_error(y_test, pred_y)\n",
    "#     r2 = r2_score(y_test, pred_y)\n",
    "#     med_ae = median_absolute_error(y_test, pred_y)\n",
    "\n",
    "#     print(\"=== Métriques globales ===\")\n",
    "#     print(f\"MSE : {mse:.2f}\")\n",
    "#     print(f\"RMSE : {rmse:.2f}\")\n",
    "#     print(f\"MAE : {mae:.2f}\")\n",
    "#     print(f\"R2 : {r2:.4f}\")\n",
    "#     print(f\"MedAE : {med_ae:.2f}\")\n",
    "\n",
    "#     # Métriques par segment d'entrées\n",
    "#     segments = [\n",
    "#         (0, 50000, \"Petit succès (<50K)\"),\n",
    "#         (50000, 200000, \"Succès moyen (50K-200K)\"),\n",
    "#         (200000, 500000, \"Grand succès (200K-500K)\"),\n",
    "#         (500000, float('inf'), \"Blockbuster (>500K)\")\n",
    "#     ]\n",
    "\n",
    "#     print(\"\\n=== Métriques par segment ===\")\n",
    "#     for low, high, label in segments:\n",
    "#         mask = (y_test >= low) & (y_test < high)\n",
    "#         if mask.sum() > 0:\n",
    "#             segment_rmse = np.sqrt(mean_squared_error(y_test[mask], pred_y[mask]))\n",
    "#             segment_mae = mean_absolute_error(y_test[mask], pred_y[mask])\n",
    "#             segment_r2 = r2_score(y_test[mask], pred_y[mask]) if mask.sum() > 1 else float('nan')\n",
    "\n",
    "#             print(f\"\\n{label} (n={mask.sum()}):\")\n",
    "#             print(f\"  RMSE : {segment_rmse:.2f}\")\n",
    "#             print(f\"  MAE : {segment_mae:.2f}\")\n",
    "#             print(f\"  R2 : {segment_r2:.4f}\")\n",
    "\n",
    "#     # Visualisation des erreurs\n",
    "#     error = y_test - pred_y\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.scatter(y_test, error, alpha=0.5)\n",
    "#     plt.axhline(y=0, color='r', linestyle='-')\n",
    "#     plt.xlabel('Entrées réelles')\n",
    "#     plt.ylabel('Erreur (Réel - Prédit)')\n",
    "#     plt.title('Erreurs de prédiction par rapport aux entrées réelles')\n",
    "#     plt.grid(True)\n",
    "#     plt.show()\n",
    "\n",
    "#     # Prédictions vs réalité\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.scatter(y_test, pred_y, alpha=0.5)\n",
    "#     plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "#     plt.xlabel('Entrées réelles')\n",
    "#     plt.ylabel('Entrées prédites')\n",
    "#     plt.title('Prédictions vs Réalité')\n",
    "#     plt.grid(True)\n",
    "#     plt.show()\n",
    "\n",
    "#     return mse, rmse, mae, r2, med_ae\n",
    "\n",
    "# # Évaluer le modèle final\n",
    "# print(\"\\nPerformances du modèle final:\")\n",
    "# metriques_detaillees(final_model, X_test, y_test)\n",
    "\n",
    "# # Importance des features\n",
    "# feature_importance = pd.DataFrame({\n",
    "#     'Feature': X_train.columns,\n",
    "#     'Importance': final_model.feature_importances_\n",
    "# }).sort_values('Importance', ascending=False)\n",
    "\n",
    "# print(\"\\nTop 20 features les plus importantes:\")\n",
    "# print(feature_importance.head(20))\n",
    "\n",
    "# # Sauvegarder le modèle\n",
    "# final_model.save_model('catboost_final_model.cbm')\n",
    "# print(\"\\nModèle sauvegardé sous 'catboost_final_model.cbm'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c6ff666c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "# # import cupy as cp\n",
    "\n",
    "# # Paramètres pour XGBoost GPU\n",
    "# xgb_params = {\n",
    "#     'n_estimators': [100, 200, 500],\n",
    "#     'learning_rate': [0.05, 0.1, 0.2],\n",
    "#     'max_depth': [4, 6, 8],\n",
    "#     'subsample': [0.8, 0.9, 1.0],\n",
    "#     'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "# }\n",
    "\n",
    "# # GridSearchCV avec XGBoost GPU\n",
    "# xgb_grid = GridSearchCV(\n",
    "#     XGBRegressor(\n",
    "#         random_state=42,\n",
    "#         enable_categorical=True,\n",
    "#         device='cuda',  # Utiliser GPU pour l'entraînement\n",
    "#     ),\n",
    "#     xgb_params,\n",
    "#     cv=5,\n",
    "#     scoring='neg_root_mean_squared_error',\n",
    "#     n_jobs=1  # Important: utilisez 1 avec GPU pour éviter les conflits\n",
    "# )\n",
    "\n",
    "# # Entraînement avec pondération des échantillons\n",
    "# sample_weights = np.ones(len(y_train))\n",
    "# success_mask = y_train > 500000\n",
    "# sample_weights[success_mask] = 5  # Pondération 3x plus importante\n",
    "\n",
    "# # X_gpu = cp.asarray(X)  # Conversion CPU → GPU\n",
    "# xgb_grid.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "# print(f\"Meilleurs paramètres XGBoost GPU: {xgb_grid.best_params_}\")\n",
    "# print(f\"Meilleur RMSE: {-xgb_grid.best_score_:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236d27fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebc352a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
